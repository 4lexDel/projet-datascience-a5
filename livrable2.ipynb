{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livrable 2 - Groupe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenu du livrable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but est de traiter un ensemble de photographies afin de les rendre mieux traitables par les algorithmes de Machine Learning. Le traitement à réaliser est une opération de débruitage. Ces algorithmes s'appuieront sur les auto-encodeurs à convolution, et les appliqueront pour améliorer la qualité de l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chargement des données provenant de l'EDA (livrable 1)\n",
    "2. Création du dataset\n",
    "3. Définition de l'autoencodeur (CAE)\n",
    "4. Entrainement\n",
    "5. Métriques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import datetime\n",
    "\n",
    "import PIL\n",
    "import imghdr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de la source de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID du fichier (extrait de l'URL)\n",
    "file_id = \"1PGTFqsXHRCXV3R2Rns6yz0QS26ihfgYM\"\n",
    "dataset_path = \"dataset_livrable_2\"\n",
    "zip_path = dataset_path + \".zip\"\n",
    "extract_dir = pathlib.Path(zip_path).parent / dataset_path\n",
    "reduce_dataset = True\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(f\"Le dossier '{extract_dir}' n'existe pas. Téléchargement en cours...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_path, quiet=False)\n",
    "\n",
    "    print(f\"Extraction ZIP en cours...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"Extraction Zip terminée\")\n",
    "else:\n",
    "    print(f\"Le dossier '{extract_dir}' existe déjà. Téléchargement et extraction non nécessaires.\")\n",
    "\n",
    "data_dir = extract_dir\n",
    "print(f\"Dataset disponible dans : {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2\n",
    "seed = 42\n",
    "\n",
    "batch_size = 128\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using image_dataset_from_directory\n",
    "\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    labels=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    labels=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in val_set.take(1):\n",
    "    print(f\"Image dimensions: {images.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImagesFromDataset(dataset, label):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for images in dataset.take(1):\n",
    "        for i in range(5):\n",
    "            ax = plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(label)\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayImagesFromDataset(train_set, \"Train Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des différents bruits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0.0, stddev=20.0):\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    noisy_image = image + noise\n",
    "    noisy_image = tf.clip_by_value(noisy_image, 0.0, 255.0)\n",
    "    noisy_image = tf.cast(noisy_image, tf.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "def add_poisson_noise(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Ajout d'une petite constante pour éviter poisson(0)\n",
    "    noisy = tf.random.poisson([], lam=image + 1e-3, dtype=tf.float32)\n",
    "    noisy = tf.clip_by_value(noisy, 0.0, 255.0)\n",
    "    return tf.cast(noisy, tf.uint8)\n",
    "\n",
    "def add_salt_pepper_noise(image, prob=0.02):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    rnd = tf.random.uniform(tf.shape(image), 0, 1)\n",
    "    \n",
    "    salt = tf.cast(rnd < prob / 2, tf.float32) * 255\n",
    "    pepper = tf.cast(rnd > 1 - prob / 2, tf.float32) * 0\n",
    "    mask = tf.cast((rnd >= prob / 2) & (rnd <= 1 - prob / 2), tf.float32)\n",
    "\n",
    "    noisy_image = image * mask + salt + pepper\n",
    "    noisy_image = tf.clip_by_value(noisy_image, 0.0, 255.0)\n",
    "    return tf.cast(noisy_image, tf.uint8)\n",
    "\n",
    "def add_uniform_noise(image, minval=-20.0, maxval=20.0):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    noise = tf.random.uniform(tf.shape(image), minval=minval, maxval=maxval, dtype=tf.float32)\n",
    "    noisy_image = image + noise\n",
    "    noisy_image = tf.clip_by_value(noisy_image, 0.0, 255.0)\n",
    "    return tf.cast(noisy_image, tf.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des différents bruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the same image with different types of noise\n",
    "def display_noisy_images(image, noise_functions):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(1, len(noise_functions) + 1, 1)\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    for i, noise_func in enumerate(noise_functions):\n",
    "        noisy_image = noise_func(image)\n",
    "        plt.subplot(1, len(noise_functions) + 1, i + 2)\n",
    "        plt.imshow(noisy_image.numpy().astype(\"uint8\"))\n",
    "        plt.title(noise_func.__name__)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "# Display a sample image with different types of noise\n",
    "sample_image = next(iter(train_set.take(1)))[0]  # Get the first image from the first batch\n",
    "noise_functions = [add_gaussian_noise, add_poisson_noise, add_salt_pepper_noise, add_uniform_noise]\n",
    "display_noisy_images(sample_image, noise_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_noise(image):\n",
    "    noise_type = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "    \n",
    "    def case0(): return add_gaussian_noise(image)\n",
    "    def case1(): return add_salt_pepper_noise(image)\n",
    "    def case2(): return add_uniform_noise(image)\n",
    "    def case3(): return add_poisson_noise(image)\n",
    "\n",
    "    return tf.switch_case(noise_type, branch_fns=[case0, case1, case2, case3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_set = train_set.map(lambda x: random_noise(x))\n",
    "noisy_val_set = val_set.map(lambda x: random_noise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Train Image\")\n",
    "        plt.axis(\"off\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "for images in noisy_train_set.take(1):\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Noisy Image\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance & pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# a_train_set = noisy_train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "# a_val_set = val_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "for image in noisy_train_set.take(1):\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "for image in noisy_val_set.take(1):\n",
    "    print(f\"Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations principales de nos modèles\n",
    "IMG_SIZE          = img_width\n",
    "NB_EPOCHS_DENOISE = 100               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE        = 128               # taille batch de traitement\n",
    "SAV_MODEL_DENOISE = \"denoiser.h5\"     # sauvegarde du modele de debruitage\n",
    "LATENT_DIM        = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "# Create a Sequential model\n",
    "encoder = Sequential([\n",
    "    Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    # layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # layers.Dropout(0.2),  # Dropout after the first pooling layer\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    # layers.Dropout(0.3),  # Dropout after the second pooling layer\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    MaxPooling2D((2, 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "# Decoding\n",
    "decoder = Sequential([\n",
    "    Input(shape=encoder.output_shape[1:]),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (1, 1), activation='sigmoid', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Autoencoder(LATENT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')\n",
    "# autoencoder.summary()\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='./L1_model.keras', save_best_only=True)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "import tensorflow as tf\n",
    "\n",
    "paired_train_set = tf.data.Dataset.zip((noisy_train_set, train_set))\n",
    "paired_val_set = tf.data.Dataset.zip((noisy_val_set, val_set))\n",
    "\n",
    "paired_train_set = paired_train_set.map(lambda noisy, clean: (tf.cast(noisy, tf.float32) / 255.0, clean / 255.0))\n",
    "paired_val_set = paired_val_set.map(lambda noisy, clean: (tf.cast(noisy, tf.float32) / 255.0, clean / 255.0))\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    paired_train_set,\n",
    "    epochs=NB_EPOCHS_DENOISE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    validation_data=(paired_val_set),\n",
    "    callbacks=[early_stopping, model_checkpoint] #tensorboard_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Courbe d'apprentisssage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des pertes d'apprentissage (Train) et de validation (Test)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize noisy and denoised images side by side in columns\n",
    "plt.figure(figsize=(15, 15))\n",
    "for noisy_images_batch, clean_images_batch in paired_val_set.take(1):\n",
    "    for i in range(5):  # Display 5 images\n",
    "        # Display noisy image\n",
    "        ax = plt.subplot(5, 2, 2 * i + 1)\n",
    "        noisy_image = noisy_images_batch[i].numpy() * 255.0  # Scale back to [0, 255]\n",
    "        plt.imshow(noisy_image.astype(\"uint8\"))\n",
    "        plt.title(\"Noisy Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Display denoised image\n",
    "        denoised_image = autoencoder(noisy_images_batch[i:i+1])  # Predict denoised image\n",
    "        denoised_image = denoised_image[0].numpy() * 255.0  # Scale back to [0, 255]\n",
    "        ax = plt.subplot(5, 2, 2 * i + 2)\n",
    "        plt.imshow(denoised_image.astype(\"uint8\"))\n",
    "        plt.title(\"Denoised Image\")\n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
