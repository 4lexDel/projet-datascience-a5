{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livrable 2 - Groupe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenu du livrable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but est de traiter un ensemble de photographies afin de les rendre mieux traitables par les algorithmes de Machine Learning. Le traitement à réaliser est une opération de débruitage. Ces algorithmes s'appuieront sur les auto-encodeurs à convolution, et les appliqueront pour améliorer la qualité de l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chargement des données provenant de l'EDA (livrable 1)\n",
    "2. Création du dataset\n",
    "3. Définition de l'autoencodeur (CAE)\n",
    "4. Entrainement\n",
    "5. Métriques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "import PIL\n",
    "import imghdr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de la source de données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie permet de récuperer le dataset depuis le drive afin d'automatiser la `pipeline`.  \n",
    "L'objectif est d'utiliser un dataset commun au sein du groupe. \n",
    "\n",
    "Ce dernier à le dossier `Sketch` complété par des données trouvés dans les sources suivantes : [croquis](https://paperswithcode.com/dataset/sketch) || [visages réalistes](https://www.kaggle.com/datasets/arbazkhan971/cuhk-face-sketch-database-cufs/data)\n",
    "\n",
    "Ce qui fait passer le dossier sketch de `606 visages` et `800 croquis` avec un ration de `43%`/`57%` entre visages/croquis à `1200 visages` et `3200 croquis` pour un ratio final équivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID du fichier (extrait de l'URL)\n",
    "file_id = \"1PGTFqsXHRCXV3R2Rns6yz0QS26ihfgYM\"\n",
    "dataset_path = \"dataset_livrable_2\"\n",
    "zip_path = dataset_path + \".zip\"\n",
    "extract_dir = pathlib.Path(zip_path).parent / dataset_path\n",
    "reduce_dataset = True\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(f\"Le dossier '{extract_dir}' n'existe pas. Téléchargement en cours...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_path, quiet=False)\n",
    "\n",
    "    print(f\"Extraction ZIP en cours...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"Extraction Zip terminée\")\n",
    "else:\n",
    "    print(f\"Le dossier '{extract_dir}' existe déjà. Téléchargement et extraction non nécessaires.\")\n",
    "\n",
    "data_dir = extract_dir\n",
    "print(f\"Dataset disponible dans : {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "# print(f\"Catégories détectées : {categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2\n",
    "seed = 42\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using image_dataset_from_directory\n",
    "\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    labels=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    labels=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in val_set.take(1):\n",
    "    print(f\"Image dimensions: {images.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Noisy Image\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0.0, stddev=70):\n",
    "    \"\"\"Applies Gaussian noise to an image.\"\"\"\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "    noisy_image = tf.cast(image, tf.float32)# / 255.0\n",
    "    noisy_image = noisy_image + noise\n",
    "    noisy_image = tf.clip_by_value(noisy_image, 0.0, 255.0)\n",
    "    return noisy_image\n",
    "\n",
    "noisy_train_set = train_set.map(lambda x: add_gaussian_noise(x))\n",
    "noisy_val_set = val_set.map(lambda x: add_gaussian_noise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images in noisy_train_set.take(1):\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Noisy Image\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance & pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# a_train_set = noisy_train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "# a_val_set = val_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "for image in noisy_train_set.take(1):\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "for image in noisy_val_set.take(1):\n",
    "    print(f\"Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations principales de nos modèles\n",
    "IMG_SIZE          = img_width\n",
    "NB_EPOCHS_DENOISE = 100               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE        = 128               # taille batch de traitement\n",
    "SAV_MODEL_DENOISE = \"denoiser.h5\"     # sauvegarde du modele de debruitage\n",
    "LATENT_DIM        = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "# Create a Sequential model\n",
    "encoder = Sequential([\n",
    "    Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    # layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.2),  # Dropout after the first pooling layer\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Dropout(0.3),  # Dropout after the second pooling layer\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    MaxPooling2D((2, 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "# Decoding #\n",
    "\n",
    "# TODO =>=>=>=>=>=>=>=>=>=>=>=>=>=>=> drop out\n",
    "\n",
    "# Create a Sequential model for the decoder\n",
    "decoder = Sequential([\n",
    "    Input(shape=encoder.output_shape[1:]),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (1, 1), activation='sigmoid', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Autoencoder(LATENT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')\n",
    "# autoencoder.summary()\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='./L1_model.keras', save_best_only=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "import tensorflow as tf\n",
    "\n",
    "paired_train_set = tf.data.Dataset.zip((noisy_train_set, train_set))\n",
    "paired_val_set = tf.data.Dataset.zip((noisy_val_set, val_set))\n",
    "\n",
    "paired_train_set = paired_train_set.map(lambda noisy, clean: (noisy / 255.0, clean / 255.0))\n",
    "paired_val_set = paired_val_set.map(lambda noisy, clean: (noisy / 255.0, clean / 255.0))\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    paired_train_set,\n",
    "    epochs=NB_EPOCHS_DENOISE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    validation_data=(paired_val_set),\n",
    "    callbacks=[early_stopping, model_checkpoint, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Courbe d'apprentisssage\n",
    "- Métrique\n",
    "- Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des pertes d'apprentissage (Train) et de validation (Test)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize noisy and denoised images side by side\n",
    "plt.figure(figsize=(15, 15))\n",
    "for noisy_images_batch, clean_images_batch in paired_val_set.take(1):\n",
    "    for i in range(5):  # Display 5 images\n",
    "        # Display noisy image\n",
    "        ax = plt.subplot(2, 5, i + 1)\n",
    "        noisy_image = noisy_images_batch[i].numpy() * 255.0  # Scale back to [0, 255]\n",
    "        plt.imshow(noisy_image.astype(\"uint8\"))\n",
    "        plt.title(\"Noisy Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Display denoised image\n",
    "        denoised_image = autoencoder(noisy_images_batch[i:i+1])  # Predict denoised image\n",
    "        denoised_image = denoised_image[0].numpy() * 255.0  # Scale back to [0, 255]\n",
    "        ax = plt.subplot(2, 5, i + 6)\n",
    "        plt.imshow(denoised_image.astype(\"uint8\"))\n",
    "        plt.title(\"Denoised Image\")\n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
