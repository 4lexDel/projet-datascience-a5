{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livrable 1 - groupe 1\n",
    "\n",
    "Nous sommes le groupe 1 composé de :  \n",
    "- DELORME Alexandre\n",
    "- ENCOGNERE Yanis\n",
    "- MENNERON Laurine\n",
    "- PEREON Alexandre\n",
    "- ROCHARD Léo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TODO\n",
    "\n",
    "##  Analyse des Résultats et Biais/VarianceAnalyse\n",
    "\n",
    "Discussion sur le surapprentissage/sous-apprentissage\n",
    "\n",
    "Calcul et affichage d'une matrice de confusion\n",
    "\n",
    "Calcul de métriques supplémentaires (précision, rappel, F1-score)\n",
    "\n",
    "## À implémenter/discuter:\n",
    "\n",
    "Régularisation L2 dans les couches denses/convolutionnelles\n",
    "\n",
    "Ajustement du taux de dropout\n",
    "\n",
    "Utilisation de Batch Normalization\n",
    "\n",
    "Transfer learning avec un modèle pré-entraîné (VGG16, ResNet, etc.)\n",
    "\n",
    "Grid search pour optimiser les hyperparamètres\n",
    "\n",
    "## Documentation et Justifications\n",
    "\n",
    "Schéma de l'architecture du réseau (peut être généré avec tf.keras.utils.plot_model)\n",
    "\n",
    "Justification des choix (architecture, hyperparamètres, etc.)\n",
    "\n",
    "Analyse des résultats obtenus\n",
    "\n",
    "Discussion sur les difficultés rencontrées (images réalistes dans les peintures)\n",
    "\n",
    "## Gestion des Données Déséquilibrées\n",
    "\n",
    "Analyse du déséquilibre entre classes photo/non-photo\n",
    "\n",
    "Techniques pour gérer le déséquilibre (poids de classe, oversampling, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T07:35:31.537249Z",
     "start_time": "2025-04-04T07:35:26.945745Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import imghdr\n",
    "import os\n",
    "import pathlib\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import visualkeras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie permet de récuperer le dataset depuis le drive afin d'automatiser la pipeline. L'objectif est d'utiliser un dataset commun au sein du groupe. \n",
    "\n",
    "Ce dernier à le dossier \"Sketch\" complété par des données trouvés dans les sources suivantes : [croquis](https://paperswithcode.com/dataset/sketch) || [visages réalistes](https://www.kaggle.com/datasets/arbazkhan971/cuhk-face-sketch-database-cufs/data)\n",
    "\n",
    "Ce qui fait passer le dossier sketch de 606 visages et 800 croquis avec un ration de 43%/57% entre visages/croquis à 1200 visages et 3200 croquis pour un ratio final équivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:00:24.968116Z",
     "start_time": "2025-04-04T09:00:24.952043Z"
    }
   },
   "outputs": [],
   "source": [
    "# ID du fichier (extrait de l'URL)\n",
    "file_id = \"1d0k3mXd93JM0fLLYrUZRr4Un1F_TnuHi\"\n",
    "dataset_path = \"dataset_livrable_1\"\n",
    "zip_path = dataset_path + \".zip\"\n",
    "extract_dir = pathlib.Path(zip_path).parent / dataset_path\n",
    "reduce_dataset = True\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(f\"Le dossier '{extract_dir}' n'existe pas. Téléchargement en cours...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_path, quiet=False)\n",
    "\n",
    "    print(f\"Extraction ZIP en cours...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"Extraction Zip terminée\")\n",
    "else:\n",
    "    print(f\"Le dossier '{extract_dir}' existe déjà. Téléchargement et extraction non nécessaires.\")\n",
    "\n",
    "data_dir = extract_dir\n",
    "print(f\"Dataset disponible dans : {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détection des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:00:28.013702Z",
     "start_time": "2025-04-04T09:00:27.998028Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "print(f\"Catégories détectées : {categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppresion des fichiers corrompus ou non images --------------------------------------------------------------------\n",
    "def clean_images_dataset(dataset_path_arg):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer le dataset en supprimant les fichiers corrompus ou non images.\n",
    "    \"\"\"\n",
    "    # Dictionnaire pour stocker le nombre d'images corrompues par classe\n",
    "    corrupted_count_by_class = defaultdict(int)\n",
    "    dataset_path = dataset_path_arg\n",
    "    print(\"Début de la vérification des images ...\")\n",
    "\n",
    "    # Récupération de toutes les images pour calculer la progression\n",
    "    all_files = []\n",
    "    for dir_name in os.listdir(dataset_path): \n",
    "        dir_path = os.path.join(dataset_path, dir_name)\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            all_files.append((dir_name, dir_path, file_name))\n",
    "\n",
    "    total_files = len(all_files)\n",
    "    checked_files = 0  # Pour la progression\n",
    "\n",
    "    # Parcours des images avec affichage de la progression\n",
    "    for dir_name, dir_path, file_name in all_files:\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            try:\n",
    "                with open(os.path.join(dir_path, file_name), 'rb') as file:\n",
    "                    img_bytes = file.read()  # Lire les bytes de l'image\n",
    "                    img = tf.image.decode_image(img_bytes)  # Essayer de décoder l'image\n",
    "            except Exception as e:\n",
    "                corrupted_count_by_class[dir_name] += 1\n",
    "                print(f\"\\nImage corrompue : {file_name} dans {dir_name}. Exception: {e}\")\n",
    "                os.remove(os.path.join(dir_path, file_name))\n",
    "                print(f\"Image {file_name} supprimée.\")\n",
    "        else:\n",
    "            corrupted_count_by_class[dir_name] += 1\n",
    "            print(f\"\\nLe fichier {file_name} dans {dir_name} n'est pas une image.\")\n",
    "            os.remove(os.path.join(dir_path, file_name))\n",
    "            print(f\"Fichier {file_name} supprimé.\")\n",
    "\n",
    "        # Mise à jour de la progression\n",
    "        checked_files += 1\n",
    "        progress = (checked_files / total_files) * 100\n",
    "        print(f\"\\rProgression : [{int(progress)}%] {checked_files}/{total_files} images vérifiées\", end=\"\")\n",
    "\n",
    "    print(\"\\nVérification des fichiers terminée.\")\n",
    "\n",
    "    # Affichage du nombre d'images corrompues par dossier\n",
    "    for dir_name, count in corrupted_count_by_class.items():\n",
    "        print(f\"Dossier {dir_name} : {count} images corrompues\")\n",
    "\n",
    "    # Nombre total d'images corrompues\n",
    "    total_corrupted = sum(corrupted_count_by_class.values())\n",
    "    print(f\"Nombre total d'images corrompues ou non image : {total_corrupted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du nombre de données par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {class_name: len(list((data_dir / class_name).glob('*'))) for class_name in categories}\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:00:37.221558Z",
     "start_time": "2025-04-04T09:00:31.491085Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_split = 0.2\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_names=categories)\n",
    "\n",
    "val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_names=categories)\n",
    "\n",
    "class_names = train_set.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes found: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des différentes classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition des classes au sein du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:01:06.917158Z",
     "start_time": "2025-04-04T09:00:46.265124Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.title(\"Class Repartition\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:02:16.678472Z",
     "start_time": "2025-04-04T09:02:16.659356Z"
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# Cette commande n'est pas nécessaire sur colab\n",
    "train_set = train_set.shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_set = val_set.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la fonction de perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:14:58.169501Z",
     "start_time": "2025-04-04T08:14:33.403747Z"
    }
   },
   "outputs": [],
   "source": [
    "total = sum(class_counts.values())\n",
    "weights = {class_name: (total / class_count) for class_name, class_count in class_counts.items()}\n",
    "\n",
    "max_weight = max(weights.values())\n",
    "class_weights = {class_name: weight / max_weight for class_name, weight in weights.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Appliquer les poids dans la fonction de perte\n",
    "class_weight_tensor = tf.constant([class_weights[class_name] for class_name in categories], dtype=tf.float32)\n",
    "\n",
    "print(\"Class_weight_tensor:\", class_weight_tensor)\n",
    "\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    weights = tf.gather(class_weight_tensor, tf.cast(y_true, tf.int32))\n",
    "    unweighted_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    return unweighted_loss * weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:15:02.651666Z",
     "start_time": "2025-04-04T08:15:02.082337Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.1, seed=42),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.1, seed=42),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.1, seed=42),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3, seed=42),\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax'), ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=weighted_loss, metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:15:09.823094Z",
     "start_time": "2025-04-04T08:15:09.797384Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='./L1_model.keras', save_best_only=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:54:17.046143Z",
     "start_time": "2025-04-04T08:15:11.712768Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_set,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_set,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping, model_checkpoint, tensorboard_callback])\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion et rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:57:47.365116Z",
     "start_time": "2025-04-04T08:57:47.333770Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_and_report(model, val_set):\n",
    "    val_predictions = model.predict(val_set)\n",
    "    val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "    val_true_labels = np.concatenate([y for x, y in val_set], axis=0)\n",
    "\n",
    "    conf_matrix = confusion_matrix(val_true_labels, val_pred_labels)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Matrice de Confusion\")\n",
    "    plt.xlabel(\"Classe Prédite\")\n",
    "    plt.ylabel(\"Classe Réelle\")\n",
    "    plt.show()\n",
    "    report = classification_report(val_true_labels, val_pred_labels, target_names=class_names)\n",
    "\n",
    "    print(\"Rapport de Classification :\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:58:06.875286Z",
     "start_time": "2025-04-04T08:57:49.458180Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix_and_report(model, val_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
