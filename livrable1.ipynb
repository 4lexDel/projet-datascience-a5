{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livrable 1 - groupe 1\n",
    "\n",
    "Nous sommes le groupe 1 composé de :  \n",
    "- DELORME Alexandre\n",
    "- ENCOGNERE Yanis\n",
    "- MENNERON Laurine\n",
    "- PEREON Alexandre\n",
    "- ROCHARD Léo\n",
    "\n",
    "## Contenu du livrable\n",
    "TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TODO\n",
    "\n",
    "##  Analyse des Résultats et Biais/VarianceAnalyse\n",
    "\n",
    "Discussion sur le surapprentissage/sous-apprentissage\n",
    "\n",
    "Calcul et affichage d'une matrice de confusion\n",
    "\n",
    "Calcul de métriques supplémentaires (précision, rappel, F1-score)\n",
    "\n",
    "## À implémenter/discuter:\n",
    "\n",
    "Régularisation L2 dans les couches denses/convolutionnelles\n",
    "\n",
    "Ajustement du taux de dropout\n",
    "\n",
    "Utilisation de Batch Normalization\n",
    "\n",
    "Transfer learning avec un modèle pré-entraîné (VGG16, ResNet, etc.)\n",
    "\n",
    "Grid search pour optimiser les hyperparamètres\n",
    "\n",
    "## Documentation et Justifications\n",
    "\n",
    "Schéma de l'architecture du réseau (peut être généré avec tf.keras.utils.plot_model)\n",
    "\n",
    "Justification des choix (architecture, hyperparamètres, etc.)\n",
    "\n",
    "Analyse des résultats obtenus\n",
    "\n",
    "Discussion sur les difficultés rencontrées (images réalistes dans les peintures)\n",
    "\n",
    "## Gestion des Données Déséquilibrées\n",
    "\n",
    "Analyse du déséquilibre entre classes photo/non-photo\n",
    "\n",
    "Techniques pour gérer le déséquilibre (poids de classe, oversampling, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "TODO...\n",
    "- Chargement du dataset\n",
    "- Visualisation\n",
    "- Répartition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:36:20.441232Z",
     "start_time": "2025-04-02T07:36:20.306412Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import imghdr\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import gdown\n",
    "import zipfile\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:47:19.281584Z",
     "start_time": "2025-04-02T07:47:19.253685Z"
    }
   },
   "outputs": [],
   "source": [
    "# ID du fichier (extrait de l'URL)\n",
    "file_id = \"1Q5QttYirEHvto38l6e6uk66Fjvuk_V7I\"\n",
    "# dataset_path = \"dataset_livrable_1\"\n",
    "dataset_path = \"dataset\"\n",
    "zip_path = dataset_path + \".zip\"\n",
    "extract_dir = pathlib.Path(zip_path).parent / dataset_path\n",
    "\n",
    "# Vérifier si le dossier existe déjà\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(f\"Le dossier '{extract_dir}' n'existe pas. Téléchargement en cours...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_path, quiet=False)\n",
    "\n",
    "    # Extraction du fichier ZIP\n",
    "    print(f\"Extraction ZIP en cours...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"Extraction Zip terminée\")\n",
    "else:\n",
    "    print(f\"Le dossier '{extract_dir}' existe déjà. Téléchargement et extraction non nécessaires.\")\n",
    "\n",
    "data_dir = extract_dir\n",
    "print(f\"Dataset disponible dans : {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:47:23.369296Z",
     "start_time": "2025-04-02T07:47:23.347705Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "print(f\"Catégories détectées : {categories}\")\n",
    "\n",
    "validation_split = 0.2\n",
    "seed = 42\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:51:56.708494Z",
     "start_time": "2025-04-02T07:48:53.063346Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Suppresion des fichiers corrompus ou non images --------------------------------------------------------------------\n",
    "def clean_images_dataset(dataset_path_arg):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer le dataset en supprimant les fichiers corrompus ou non images.\n",
    "    \"\"\"\n",
    "    # Dictionnaire pour stocker le nombre d'images corrompues par classe\n",
    "    corrupted_count_by_class = defaultdict(int)\n",
    "    dataset_path = dataset_path_arg\n",
    "    print(\"Début de la vérification des images ...\")\n",
    "\n",
    "    # Récupération de toutes les images pour calculer la progression\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(dataset_path):  # Utilisation de os.walk pour parcourir récursivement\n",
    "        for file_name in files:\n",
    "            dir_name = os.path.basename(root)  # Nom du dossier courant\n",
    "            all_files.append((dir_name, root, file_name))\n",
    "\n",
    "    total_files = len(all_files)\n",
    "    checked_files = 0  # Pour la progression\n",
    "\n",
    "    # Parcours des images avec affichage de la progression\n",
    "    for dir_name, dir_path, file_name in all_files:\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            try:\n",
    "                with open(os.path.join(dir_path, file_name), 'rb') as file:\n",
    "                    img_bytes = file.read()  # Lire les bytes de l'image\n",
    "                    img = tf.image.decode_image(img_bytes)  # Essayer de décoder l'image\n",
    "            except Exception as e:\n",
    "                corrupted_count_by_class[dir_name] += 1\n",
    "                print(f\"\\nImage corrompue : {file_name} dans {dir_name}. Exception: {e}\")\n",
    "                os.remove(os.path.join(dir_path, file_name))\n",
    "                print(f\"Image {file_name} supprimée.\")\n",
    "        else:\n",
    "            corrupted_count_by_class[dir_name] += 1\n",
    "            print(f\"\\nLe fichier {file_name} dans {dir_name} n'est pas une image.\")\n",
    "            os.remove(os.path.join(dir_path, file_name))\n",
    "            print(f\"Fichier {file_name} supprimé.\")\n",
    "\n",
    "        # Mise à jour de la progression\n",
    "        checked_files += 1\n",
    "        progress = (checked_files / total_files) * 100\n",
    "        print(f\"\\rProgression : [{int(progress)}%] {checked_files}/{total_files} images vérifiées\", end=\"\")\n",
    "\n",
    "    print(\"\\nVérification des fichiers terminée.\")\n",
    "\n",
    "    # Affichage du nombre d'images corrompues par dossier\n",
    "    for dir_name, count in corrupted_count_by_class.items():\n",
    "        print(f\"Dossier {dir_name} : {count} images corrompues\")\n",
    "\n",
    "    # Nombre total d'images corrompues\n",
    "    total_corrupted = sum(corrupted_count_by_class.values())\n",
    "    print(f\"Nombre total d'images corrompues ou non image : {total_corrupted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_images_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:54:09.177396Z",
     "start_time": "2025-04-02T07:54:09.114886Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_names=categories)\n",
    "\n",
    "val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_names=categories)\n",
    "\n",
    "class_names = train_set.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes found: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_foreach_label(dataset):\n",
    "    label_counts = Counter(class_names[label] for _, labels in dataset for label in labels)\n",
    "    return dict(label_counts)\n",
    "\n",
    "# Count labels in train and validation sets\n",
    "train_label_counts = count_images_foreach_label(train_set)\n",
    "val_label_counts = count_images_foreach_label(val_set)\n",
    "\n",
    "# Extract data for plotting\n",
    "labels, train_counts = zip(*train_label_counts.items())\n",
    "\n",
    "# Print counts\n",
    "print(train_label_counts)\n",
    "\n",
    "# Plot Train Set Distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(labels, train_counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Train Set')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_set = val_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Étape 1 : Calculer les poids pour chaque classe\n",
    "def compute_class_weights(dataset, class_names):\n",
    "    \"\"\"\n",
    "    Calcule les poids pour chaque classe en fonction de leur fréquence dans le dataset.\n",
    "    \"\"\"\n",
    "    label_counts = Counter(class_names[label] for _, labels in dataset for label in labels)\n",
    "    total_samples = sum(label_counts.values())\n",
    "    class_weights = {class_name: total_samples / count for class_name, count in label_counts.items()}\n",
    "    return class_weights\n",
    "\n",
    "# Calcul des poids pour l'ensemble d'entraînement\n",
    "class_weights = compute_class_weights(train_set, class_names)\n",
    "\n",
    "# Normaliser les poids pour éviter des valeurs trop grandes\n",
    "max_weight = max(class_weights.values())\n",
    "class_weights = {class_name: weight / max_weight for class_name, weight in class_weights.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Étape 2 : Appliquer les poids dans la fonction de perte\n",
    "# Exemple : Si vous utilisez une perte catégorielle\n",
    "class_weight_tensor = tf.constant([class_weights[class_name] for class_name in class_names], dtype=tf.float32)\n",
    "\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fonction de perte pondérée par classe pour des étiquettes entières.\n",
    "    \"\"\"\n",
    "    weights = tf.gather(class_weight_tensor, tf.cast(y_true, tf.int32))\n",
    "    unweighted_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    return unweighted_loss * weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le modèle\n",
    "model = Sequential()\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Ajout des couches au modèle\n",
    "model.add(data_augmentation)\n",
    "model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "model.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))  # Ajout de la couche Dropout\n",
    "model.add(layers.Dense(num_classes))\n",
    "\n",
    "# Compilation du modèle\n",
    "# model.compile(optimizer = 'adam',\n",
    "#               loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               # loss=weighted_categorical_crossentropy,\n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss=weighted_loss, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition du early callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='./L1_model.keras', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=4\n",
    "\n",
    "history = model.fit(train_set, \n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=val_set,\n",
    "          verbose=1, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
